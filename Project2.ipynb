{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca408ea-5a7a-4978-8809-7b888080482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter label (e.g., 'hello', 'pause', 'thank'):  tea\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∏Å‡∏î 's' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î | ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\n",
      "‚úÖ Saved: sign_data\\tea\\0.npy\n",
      "‚úÖ Saved: sign_data\\tea\\1.npy\n",
      "‚úÖ Saved: sign_data\\tea\\2.npy\n",
      "‚úÖ Saved: sign_data\\tea\\3.npy\n",
      "‚úÖ Saved: sign_data\\tea\\4.npy\n",
      "‚úÖ Saved: sign_data\\tea\\5.npy\n",
      "‚úÖ Saved: sign_data\\tea\\6.npy\n",
      "‚úÖ Saved: sign_data\\tea\\7.npy\n",
      "‚úÖ Saved: sign_data\\tea\\8.npy\n",
      "‚úÖ Saved: sign_data\\tea\\9.npy\n",
      "‚úÖ Saved: sign_data\\tea\\10.npy\n",
      "‚úÖ Saved: sign_data\\tea\\11.npy\n",
      "‚úÖ Saved: sign_data\\tea\\12.npy\n",
      "‚úÖ Saved: sign_data\\tea\\13.npy\n",
      "‚úÖ Saved: sign_data\\tea\\14.npy\n",
      "‚úÖ Saved: sign_data\\tea\\15.npy\n",
      "‚úÖ Saved: sign_data\\tea\\16.npy\n",
      "‚úÖ Saved: sign_data\\tea\\17.npy\n",
      "‚úÖ Saved: sign_data\\tea\\18.npy\n",
      "‚úÖ Saved: sign_data\\tea\\19.npy\n",
      "‚úÖ Saved: sign_data\\tea\\20.npy\n",
      "‚úÖ Saved: sign_data\\tea\\21.npy\n",
      "‚úÖ Saved: sign_data\\tea\\22.npy\n",
      "‚úÖ Saved: sign_data\\tea\\23.npy\n",
      "‚úÖ Saved: sign_data\\tea\\24.npy\n",
      "‚úÖ Saved: sign_data\\tea\\25.npy\n",
      "‚úÖ Saved: sign_data\\tea\\26.npy\n",
      "‚úÖ Saved: sign_data\\tea\\27.npy\n",
      "‚úÖ Saved: sign_data\\tea\\28.npy\n",
      "‚úÖ Saved: sign_data\\tea\\29.npy\n",
      "‚úÖ Saved: sign_data\\tea\\30.npy\n",
      "‚úÖ Saved: sign_data\\tea\\31.npy\n",
      "‚úÖ Saved: sign_data\\tea\\32.npy\n",
      "‚úÖ Saved: sign_data\\tea\\33.npy\n",
      "‚úÖ Saved: sign_data\\tea\\34.npy\n",
      "‚úÖ Saved: sign_data\\tea\\35.npy\n",
      "‚úÖ Saved: sign_data\\tea\\36.npy\n",
      "‚úÖ Saved: sign_data\\tea\\37.npy\n",
      "‚úÖ Saved: sign_data\\tea\\38.npy\n",
      "‚úÖ Saved: sign_data\\tea\\39.npy\n",
      "‚úÖ Saved: sign_data\\tea\\40.npy\n",
      "‚úÖ Saved: sign_data\\tea\\41.npy\n",
      "‚úÖ Saved: sign_data\\tea\\42.npy\n",
      "‚úÖ Saved: sign_data\\tea\\43.npy\n",
      "‚úÖ Saved: sign_data\\tea\\44.npy\n",
      "‚úÖ Saved: sign_data\\tea\\45.npy\n",
      "‚úÖ Saved: sign_data\\tea\\46.npy\n",
      "‚úÖ Saved: sign_data\\tea\\47.npy\n",
      "‚úÖ Saved: sign_data\\tea\\48.npy\n",
      "‚úÖ Saved: sign_data\\tea\\49.npy\n",
      "‚úÖ Saved: sign_data\\tea\\50.npy\n",
      "‚úÖ Saved: sign_data\\tea\\51.npy\n",
      "‚úÖ Saved: sign_data\\tea\\52.npy\n",
      "‚úÖ Saved: sign_data\\tea\\53.npy\n",
      "‚úÖ Saved: sign_data\\tea\\54.npy\n",
      "‚úÖ Saved: sign_data\\tea\\55.npy\n",
      "‚úÖ Saved: sign_data\\tea\\56.npy\n",
      "‚úÖ Saved: sign_data\\tea\\57.npy\n",
      "‚úÖ Saved: sign_data\\tea\\58.npy\n",
      "‚úÖ Saved: sign_data\\tea\\59.npy\n",
      "‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "# ‚öôÔ∏è CONFIG\n",
    "DATA_DIR = \"sign_data\"\n",
    "label = input(\"Enter label (e.g., 'hello', 'pause', 'thank'): \").strip()\n",
    "label_dir = os.path.join(DATA_DIR, label)\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "max_sequences = 60\n",
    "frames_per_seq = 30\n",
    "\n",
    "# MediaPipe\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "sequence = []\n",
    "seq_count = 0\n",
    "recording = False\n",
    "countdown = False\n",
    "countdown_start = 0\n",
    "\n",
    "print(\"‡∏Å‡∏î 's' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î | ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # ‡∏ß‡∏≤‡∏î Landmark\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_draw.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_draw.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    if results.pose_landmarks:\n",
    "        mp_draw.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    if results.face_landmarks:\n",
    "        mp_draw.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "\n",
    "    # ‡∏î‡∏∂‡∏á keypoints\n",
    "    keypoints = []\n",
    "    def extract(lms, count):\n",
    "        return [[lm.x, lm.y, lm.z] for lm in lms.landmark] if lms else [[0, 0, 0]] * count\n",
    "\n",
    "    keypoints += extract(results.face_landmarks, 468)\n",
    "    keypoints += extract(results.left_hand_landmarks, 21)\n",
    "    keypoints += extract(results.right_hand_landmarks, 21)\n",
    "    keypoints += extract(results.pose_landmarks, 33)\n",
    "\n",
    "    keypoints = np.array(keypoints).flatten()\n",
    "\n",
    "    # Countdown once before recording starts\n",
    "    if countdown:\n",
    "        elapsed = time.time() - countdown_start\n",
    "        remaining = int(3 - elapsed)\n",
    "        if remaining > 0:\n",
    "            cv2.putText(image, f\"Starting in {remaining}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            countdown = False\n",
    "            recording = True\n",
    "\n",
    "    # Recording mode: auto collect all sequences\n",
    "    if recording:\n",
    "        sequence.append(keypoints)\n",
    "        cv2.putText(image, f\"Recording... Frame {len(sequence)}/30\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if len(sequence) == frames_per_seq:\n",
    "            save_path = os.path.join(label_dir, f\"{seq_count}.npy\")\n",
    "            np.save(save_path, sequence)\n",
    "            print(f\"‚úÖ Saved: {save_path}\")\n",
    "            seq_count += 1\n",
    "            sequence = []\n",
    "        if seq_count == max_sequences:\n",
    "            print(\"‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß\"); recording = False\n",
    "\n",
    "    # UI\n",
    "    cv2.putText(image, f\"Label: {label} | Sequence: {seq_count}/{max_sequences}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "    cv2.imshow(\"Dataset Collector\", image)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('s') and not countdown and not recording and seq_count < max_sequences:\n",
    "        countdown = True\n",
    "        countdown_start = time.time()\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3fea66a-3b2e-4d0d-a572-ba40c6dcd5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå label_map: {'I': 0, 'hello': 1, 'need': 2, 'pause': 3, 'tea': 4}\n",
      "\n",
      "‚úÖ Loaded 300 sequences, shape = (300, 30, 1629), labels = 5\n",
      "\n",
      "üéØ Train Shape: (240, 30, 1629)\n",
      "üéØ Val Shape: (60, 30, 1629)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------\n",
    "# üîß CONFIG\n",
    "DATA_DIR = \"sign_data\"  # ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ\n",
    "LABELS = sorted(os.listdir(DATA_DIR))  # ['hello', 'pause', ...]\n",
    "label_map = {label: idx for idx, label in enumerate(LABELS)}\n",
    "print(\"üìå label_map:\", label_map)\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "# -----------------------------\n",
    "# üì• LOAD DATA\n",
    "for label in LABELS:\n",
    "    folder_path = os.path.join(DATA_DIR, label)\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        data = np.load(os.path.join(folder_path, file))  # shape (30, 1629)\n",
    "        if data.shape == (30, 1629):  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢\n",
    "            X.append(data)\n",
    "            y.append(label_map[label])\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipped: {file} (shape = {data.shape})\")\n",
    "\n",
    "X = np.array(X)  # shape = (N, 30, 1629)\n",
    "y = np.array(y)\n",
    "print(f\"\\n‚úÖ Loaded {X.shape[0]} sequences, shape = {X.shape}, labels = {len(np.unique(y))}\")\n",
    "\n",
    "# -----------------------------\n",
    "# üîÄ SPLIT TRAIN / VAL (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nüéØ Train Shape:\", X_train.shape)\n",
    "print(\"üéØ Val Shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d216c5-dd65-4599-9ba4-43008a36e32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved all dataset files successfully!\n"
     ]
    }
   ],
   "source": [
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"X_val.npy\", X_val)\n",
    "np.save(\"y_val.npy\", y_val)\n",
    "\n",
    "print(\"‚úÖ Saved all dataset files successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c45df5-ebc9-4a9a-b273-a18f4afd3bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: (240, 30, 1629) (240,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "X_val = np.load(\"X_val.npy\")\n",
    "y_val = np.load(\"y_val.npy\")\n",
    "\n",
    "print(\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:\", X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5b1e92c-5a68-43a6-b020-fab223f1038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1177 - loss: 1.6469 - val_accuracy: 0.2000 - val_loss: 1.6103\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2221 - loss: 1.6087 - val_accuracy: 0.2000 - val_loss: 1.6076\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2114 - loss: 1.6173 - val_accuracy: 0.2000 - val_loss: 1.6039\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1679 - loss: 1.6152 - val_accuracy: 0.2000 - val_loss: 1.6036\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2124 - loss: 1.6161 - val_accuracy: 0.4000 - val_loss: 1.5971\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2276 - loss: 1.6001 - val_accuracy: 0.3500 - val_loss: 1.5827\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2332 - loss: 1.5940 - val_accuracy: 0.4000 - val_loss: 1.5529\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4155 - loss: 1.5293 - val_accuracy: 0.5500 - val_loss: 1.3559\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4516 - loss: 1.3160 - val_accuracy: 0.4000 - val_loss: 1.1981\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3804 - loss: 1.3494 - val_accuracy: 0.5333 - val_loss: 1.1709\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4434 - loss: 1.2058 - val_accuracy: 0.7000 - val_loss: 1.0402\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4668 - loss: 1.1631 - val_accuracy: 0.6167 - val_loss: 0.8546\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5557 - loss: 0.9778 - val_accuracy: 0.6500 - val_loss: 1.0132\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5518 - loss: 1.0393 - val_accuracy: 0.8000 - val_loss: 0.6600\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5770 - loss: 0.9708 - val_accuracy: 0.6167 - val_loss: 0.7359\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5356 - loss: 0.9452 - val_accuracy: 0.6000 - val_loss: 0.7526\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7490 - loss: 0.6623 - val_accuracy: 0.8333 - val_loss: 0.4669\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7038 - loss: 0.6713 - val_accuracy: 0.8667 - val_loss: 0.4227\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8094 - loss: 0.4799 - val_accuracy: 0.8833 - val_loss: 0.3495\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8344 - loss: 0.4595 - val_accuracy: 0.9000 - val_loss: 0.3700\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8555 - loss: 0.3543 - val_accuracy: 0.9167 - val_loss: 0.3060\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8767 - loss: 0.3542 - val_accuracy: 0.8000 - val_loss: 0.4480\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7949 - loss: 0.5080 - val_accuracy: 0.7833 - val_loss: 0.4757\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8609 - loss: 0.3948 - val_accuracy: 0.8000 - val_loss: 0.4223\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8699 - loss: 0.3487 - val_accuracy: 0.8667 - val_loss: 0.4034\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8856 - loss: 0.3623 - val_accuracy: 0.9500 - val_loss: 0.2954\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9129 - loss: 0.2823 - val_accuracy: 0.9500 - val_loss: 0.2910\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8727 - loss: 0.3645 - val_accuracy: 0.8833 - val_loss: 0.3130\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9383 - loss: 0.2377 - val_accuracy: 0.9500 - val_loss: 0.2062\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8919 - loss: 0.3494 - val_accuracy: 0.7833 - val_loss: 0.5353\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8378 - loss: 0.4057 - val_accuracy: 0.7333 - val_loss: 0.6898\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7568 - loss: 0.7562 - val_accuracy: 0.8167 - val_loss: 0.4574\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8510 - loss: 0.3432 - val_accuracy: 0.9167 - val_loss: 0.2809\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8763 - loss: 0.3843 - val_accuracy: 0.9500 - val_loss: 0.2271\n",
      "‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# üîß Model Architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(30, 1629)),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')  # auto match 5 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ‚è±Ô∏è Callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# üöÄ Train\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop],\n",
    "                    batch_size=16)\n",
    "\n",
    "# üíæ Save\n",
    "model.save(\"sign_language_model.keras\")\n",
    "print(\"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165ca5b0-e0ba-40a3-b888-4a37c110b04d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Acc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b21ae-7d63-4623-ab99-49c6b5607d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget, QVBoxLayout\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QTimer\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° label\n",
    "model = tf.keras.models.load_model(\"sign_language_model.keras\")\n",
    "LABELS = ['hello', 'I', 'need', 'pause', 'tea']  # ‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏û‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô\n",
    "label_map = {i: label for i, label in enumerate(LABELS)}\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "class SignApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"Sign Language Detection with Pause\")\n",
    "        self.setGeometry(100, 100, 800, 600)\n",
    "\n",
    "        self.image_label = QLabel(self)\n",
    "        self.status_label = QLabel(\"Status: Waiting for sign\")\n",
    "        self.sentence_label = QLabel(\"\")\n",
    "        self.status_label.setStyleSheet(\"font-size: 18px; color: blue\")\n",
    "        self.sentence_label.setStyleSheet(\"font-size: 22px; color: green\")\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        layout.addWidget(self.status_label)\n",
    "        layout.addWidget(self.sentence_label)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.timer.start(30)\n",
    "\n",
    "        self.sequence = []\n",
    "        self.sentence = []\n",
    "        self.waiting_for_pause = False\n",
    "        self.last_label = None\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(rgb)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # ‡πÅ‡∏Å‡πâ‡∏™‡∏µ‡∏ü‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "\n",
    "        keypoints = []\n",
    "        def extract(lms, count):\n",
    "            return [[lm.x, lm.y, lm.z] for lm in lms.landmark] if lms else [[0, 0, 0]] * count\n",
    "\n",
    "        keypoints += extract(results.face_landmarks, 468)\n",
    "        keypoints += extract(results.left_hand_landmarks, 21)\n",
    "        keypoints += extract(results.right_hand_landmarks, 21)\n",
    "        keypoints += extract(results.pose_landmarks, 33)\n",
    "        keypoints = np.array(keypoints).flatten()\n",
    "\n",
    "        # ‡πÄ‡∏Å‡πá‡∏ö frame ‡∏•‡∏á sequence\n",
    "        self.sequence.append(keypoints)\n",
    "        if len(self.sequence) > 30:\n",
    "            self.sequence.pop(0)\n",
    "\n",
    "        if len(self.sequence) == 30:\n",
    "            input_data = np.array(self.sequence).reshape(1, 30, 1629)\n",
    "            prediction = model.predict(input_data, verbose=0)\n",
    "            confidence = np.max(prediction)\n",
    "            label = label_map[np.argmax(prediction)]\n",
    "\n",
    "            if confidence > 0.85:\n",
    "                if not self.waiting_for_pause:\n",
    "                    if label != \"pause\" and label != self.last_label:\n",
    "                        self.sentence.append(label)\n",
    "                        self.waiting_for_pause = True\n",
    "                        self.status_label.setText(f\"Detected: {label} ‚Üí Waiting for pause...\")\n",
    "                        self.last_label = label\n",
    "                else:\n",
    "                    if label == \"pause\":\n",
    "                        self.sentence.append(\"|\")\n",
    "                        self.waiting_for_pause = False\n",
    "                        self.status_label.setText(\"‚úÖ Pause detected. Ready for next sign.\")\n",
    "                        self.last_label = None\n",
    "\n",
    "        self.sentence_label.setText(\" \".join([s for s in self.sentence if s != \"|\"]))\n",
    "\n",
    "        h, w, ch = image.shape\n",
    "        bytes_per_line = ch * w\n",
    "        q_img = QImage(image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        self.image_label.setPixmap(QPixmap.fromImage(q_img))\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    window = SignApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a29af-fcdd-4c09-8e5a-9d13a08beadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
